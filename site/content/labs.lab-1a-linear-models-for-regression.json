{"version":3,"kind":"Notebook","sha256":"4e52563e5a0deeffd060432ecf176002d5d523fbb312f59c01e4b12510761f45","slug":"labs.lab-1a-linear-models-for-regression","location":"/labs/Lab 1a - Linear Models for Regression.ipynb","dependencies":[],"frontmatter":{"title":"Lab 1a: Linear regression","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"github":"https://github.com/ml-course/master","copyright":"2025. CC0 Licensed - Use as you like. Appropriate credit is very welcome","numbering":{"title":{"offset":1}},"source_url":"https://github.com/ml-course/master/blob/master/labs/Lab 1a - Linear Models for Regression.ipynb","edit_url":"https://github.com/ml-course/master/edit/master/labs/Lab 1a - Linear Models for Regression.ipynb","exports":[{"format":"ipynb","filename":"Lab 1a - Linear Models for Regression.ipynb","url":"/Lab 1a - Linear Mode-b5d79308229dc21a6c3a740ec1b66e15.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VlXGy67G5t"},{"type":"link","url":"https://www.openml.org/d/547","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"NO2 dataset","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZyIXNpomKF"}],"urlSource":"https://www.openml.org/d/547","key":"CTJowBbYGr"},{"type":"text","value":" contains 500 measurement of pollution caused by cars. The goal is to predict the concentration of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uqTEB0if5j"},{"type":"inlineMath","value":"NO_2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><msub><mi>O</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">NO_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>","key":"RJ6z1FkjyI"},{"type":"text","value":" from data about traffic and atmospheric conditions. The predictive variables include the number of cars per hour, temperature, wind, and time of day.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KrhjsXIXbV"}],"key":"NOAO5p4Gpd"}],"key":"SFHMtuXeDN"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Auto-setup when running on Google Colab\nif 'google.colab' in str(get_ipython()):\n    !pip install openml\n\n# General imports\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport openml as oml\nfrom matplotlib import cm\n\n# Hide convergence warning for now\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)","key":"CPXeJVmUlP"},{"type":"outputs","id":"niSkVfe205rEPqsmfeFpv","children":[],"key":"o2Wtyc3cCH"}],"key":"oRJicnTd6h"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Download NO2 data. Takes a while the first time.\nno2 = oml.datasets.get_dataset(547)\nX, y, _, _ = no2.get_data(target=no2.default_target_attribute); \nattribute_names = list(X)","key":"uVutoySWv4"},{"type":"outputs","id":"x8-vPUu1aaynEADC9cjAJ","children":[],"key":"sO0TTqXgW4"}],"key":"BSARuRwlwu"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Quick visualization","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DFVskiri2I"}],"identifier":"quick-visualization","label":"Quick visualization","html_id":"quick-visualization","implicit":true,"key":"xrBfWfwFaR"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"We can use pandas to quickly visualize the data. If you are new to pandas, take some time to understand the code.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"gTVimzcgDS"}],"key":"uNWctyXGfC"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"We’ll remove the ‘day’ feature to focus on the non-temporal aspects of this interaction. We are not aiming to predict future levels, and even if we would it would require special treatment (e.g. different train-test splits). There also doesn’t seem to be a long term trend in the data, even though there are clear periodic trends in temperature.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"W9JS3q23s3"}],"key":"NJspG2jOUJ"}],"key":"CpsqyHcgs0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"df = pd.DataFrame(X, columns=attribute_names).join(pd.DataFrame(list(y),columns=['target']))\ndf = df.sort_values(['day','hour_of_day']).drop('day',axis=1)\ndf.plot(use_index=False,figsize=(20,5),cmap=cm.get_cmap('brg'));\nX = X.drop('day',axis=1)","key":"uIkMZWLn0z"},{"type":"outputs","id":"vkkchAmLyNLgDsmfbzGPw","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"7867ed7601066adb54086daf77df0da5","path":"/7867ed7601066adb54086daf77df0da5.png"},"text/plain":{"content":"<Figure size 1440x360 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"eR98LY4qGk"}],"key":"KWR20DKdNg"}],"key":"rVf4Yobzxe"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"df.head()","key":"PDSpw2B20m"},{"type":"outputs","id":"EiAvpALZDMiP5tVtP9ndo","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":4,"metadata":{},"data":{"text/html":{"content":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cars_per_hour</th>\n      <th>temperature_at_2m</th>\n      <th>wind_speed</th>\n      <th>temperature_diff_2m_25m</th>\n      <th>wind_direction</th>\n      <th>hour_of_day</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>42</th>\n      <td>7.64300</td>\n      <td>8.5</td>\n      <td>4.3</td>\n      <td>-0.2</td>\n      <td>322.0</td>\n      <td>13</td>\n      <td>3.22287</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>7.75061</td>\n      <td>8.2</td>\n      <td>4.5</td>\n      <td>0.2</td>\n      <td>307.0</td>\n      <td>14</td>\n      <td>3.15274</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>8.12415</td>\n      <td>5.2</td>\n      <td>2.8</td>\n      <td>0.3</td>\n      <td>209.0</td>\n      <td>8</td>\n      <td>4.19570</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>7.64108</td>\n      <td>6.7</td>\n      <td>2.3</td>\n      <td>-0.4</td>\n      <td>247.0</td>\n      <td>10</td>\n      <td>3.98155</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>8.31630</td>\n      <td>6.3</td>\n      <td>1.2</td>\n      <td>1.3</td>\n      <td>265.0</td>\n      <td>17</td>\n      <td>4.14155</td>\n    </tr>\n  </tbody>\n</table>\n</div>","content_type":"text/html"},"text/plain":{"content":"     cars_per_hour  temperature_at_2m  wind_speed  temperature_diff_2m_25m  \\\n42         7.64300                8.5         4.3                     -0.2   \n20         7.75061                8.2         4.5                      0.2   \n255        8.12415                5.2         2.8                      0.3   \n488        7.64108                6.7         2.3                     -0.4   \n94         8.31630                6.3         1.2                      1.3   \n\n     wind_direction  hour_of_day   target  \n42            322.0           13  3.22287  \n20            307.0           14  3.15274  \n255           209.0            8  4.19570  \n488           247.0           10  3.98155  \n94            265.0           17  4.14155  ","content_type":"text/plain"}}},"children":[],"key":"PXxwE6tK2Y"}],"key":"chj5gegxpt"}],"key":"S6T0N93b3n"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"If we plot the data, ordered by time of measurement, we can see that the wind direction (measured in angular degrees) is scaled very differently from the other features. Let’s now zoom in to the other measures:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OC73PkG7UP"}],"key":"SofUICAZBh"}],"key":"EtwZyeFmjS"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"df.drop('wind_direction',axis=1).plot(use_index=False,figsize=(20,5),cmap=cm.get_cmap('brg'));","key":"ur6VOSu16i"},{"type":"outputs","id":"q0Yq5__Z9t5yZMY6T2Cj-","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"c2fa9cafb05ae59e8d95ddfb4eecc054","path":"/c2fa9cafb05ae59e8d95ddfb4eecc054.png"},"text/plain":{"content":"<Figure size 1440x360 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"gOBwiBkcH0"}],"key":"ppJGuUKAgh"}],"key":"cdMNZc3Nwg"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can see that the target (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"opKfhtIQa8"},{"type":"inlineMath","value":"NO_2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><msub><mi>O</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">NO_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>","key":"RtLVUyQKud"},{"type":"text","value":" levels) seem to be correlated to the number of cars per hour, which makes sense because cars produce ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fUCOCAYBC9"},{"type":"inlineMath","value":"NO_2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><msub><mi>O</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">NO_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>","key":"qfJmG2bbhn"},{"type":"text","value":". Other influences (air temperature differences and wind) seem to have a more complex and subtle effect. Let’s try to model these using linear regression models.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kafaGm6nNe"}],"key":"wgBhrlCufa"}],"key":"ZDzztWYMkZ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exercise 1: Model benchmark","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NVZa9ENrRI"}],"identifier":"exercise-1-model-benchmark","label":"Exercise 1: Model benchmark","html_id":"exercise-1-model-benchmark","implicit":true,"key":"RBBq9kKZGq"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"It is clear that ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"UfLsOk5Yk6"},{"type":"inlineMath","value":"NO_2","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><msub><mi>O</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">NO_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>","key":"Y4gRRXRqMK"},{"type":"text","value":" concentrations depend on a combination of these features, so we will now try to learn this complex relationship. We first evaluate a range of linear regression problems, i.e. Linear Regression, Ridge, Lasso and ElasticNet, as well as kNN. Since we observed that some features have very different scales, we’ll also build pipelines of all these measures with an additional scaling step. For now, we’ll stick to the default hyperparameter settings.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"msCiPztbZ1"}],"key":"sCTsaYZA6P"}],"key":"ULPl03HuYm"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exercise 1.1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AE7kv73Shu"}],"identifier":"exercise-1-1","label":"Exercise 1.1","html_id":"exercise-1-1","implicit":true,"key":"zKtq5Cz5A7"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Implement a function below which evaluates each classifier passed into it on the given data, and then returns both the train and test scores of each as a list. You are allowed to import additional functions from whichever module you like, but you should be able to complete the function with ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ddxwkbTrsj"},{"type":"link","url":"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"inlineCode","value":"cross_validate","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"g82lzDSjQx"}],"urlSource":"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html","key":"ezEyHwKGSG"},{"type":"text","value":" function and standard Python built-ins. Below you the function you will find example output.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"DvaWt25NBd"}],"key":"h6oA6sB1e8"}],"key":"gnm0bIIT97"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def evaluate_learners(models, X, y):\n    \"\"\"     \n    Given a list of models [model1, model2, ..., modelN] return two lists:\n     - a list with the scores obtained on the training samples for each model,\n     - a list with the test scores obtained on the test samples for each model.\n     The order of scores should match the order in which the models were originally provided. E.g.:     \n     [Model1 train score, ..., ModelN train score], [Model1 test score, ..., ModelN test score]\n    \"\"\"\n    pass\n\n# # Example output:\n# train_scores, test_scores = ([[0.92 , 0.924, 0.916, 0.917, 0.921],  # Model 1 train score for each of 5 folds.\n#                               [0.963, 0.962, 0.953, 0.912, 0.934],  # Model 2 train score for each of 5 folds.\n#                               ..\n#                              [[0.801, 0.811, 0.806, 0.826, 0.804],  # Model 1 test score for each of 5 folds.\n#                               [0.766, 0.756, 0.773, 0.756, 0.741],  # Model 2 test score for each of 5 folds.\n#                               ..","key":"CAGonFSKqR"},{"type":"outputs","id":"jLBSemjM9aZZeIj4jx3ck","children":[],"key":"DoJll1h534"}],"key":"fAhhAIXsdI"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exercise 1.2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AWMd81ekcm"}],"identifier":"exercise-1-2","label":"Exercise 1.2","html_id":"exercise-1-2","implicit":true,"key":"qAsrk8mnYU"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Call the function you created with a Linear Regression, Ridge, Lasso and ElasticNet, as well as kNN.\nStore the return values in the variables ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"JtVG8pr384"},{"type":"inlineCode","value":"train_scores","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"otoE8UP9p6"},{"type":"text","value":" and ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"tLefk0t3f2"},{"type":"inlineCode","value":"test_scores","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"LsMH7e5m1x"},{"type":"text","value":". Then, run the code given below to produce a plot visualizing the scores.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"TNeynuQXYC"}],"key":"kMWwosWusH"}],"key":"srXvo5X27g"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from sklearn.linear_model import LinearRegression\n\n# Dummy code. Replace with the actual classifiers and scores\nmodels = [LinearRegression()]\ntrain_scores, test_scores = [[0.6,0.7,0.8]], [[0.5,0.6,0.7]]","key":"KolaLtEr7w"},{"type":"outputs","id":"BiijO9x7bkvNrAnRoqexM","children":[],"key":"OH9OVk90jZ"}],"key":"k3alVp804A"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plot a bar chart of the train and test scores of all the classifiers, including the variance as error bars\nfig, ax = plt.subplots(figsize=(10,6))\nwidth=0.45\n\nax.barh(np.arange(len(train_scores)), np.mean(test_scores, axis=1), width,\n        yerr= np.std(test_scores, axis=1), color='green', label='test R^2')\nax.barh(np.arange(len(train_scores))-width, np.mean(train_scores, axis=1), width,\n        yerr= np.std(train_scores, axis=1), color='red', label='train R^2')\nfor i, te, tr in zip(np.arange(len(train_scores)),test_scores,train_scores):\n    ax.text(0, i, \"{:.3f} +- {:.3f}\".format(np.mean(te),np.std(te)), color=('white' if np.mean(te)>0.1 else 'black'), va='center')\n    ax.text(0, i-width, \"{:.3f} +- {:.3f}\".format(np.mean(tr),np.std(tr)), color=('white' if np.mean(tr)>0.1 else 'black'), va='center')\nlabels = [c.__class__.__name__ if not hasattr(c, 'steps') else c.steps[0][0] + \"_\" + c.steps[1][0] for c in models]\nax.set(yticks=np.arange(len(train_scores))-width/2, yticklabels=labels)\nax.legend(bbox_to_anchor=(1.05, 1), loc=2)\n\nplt.show()","key":"Jw3oTS7uyf"},{"type":"outputs","id":"PFcsCYGJC0lbgP8Qne9d9","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"0036aa119d57a1193bcc2204ebe27077","path":"/0036aa119d57a1193bcc2204ebe27077.png"},"text/plain":{"content":"<Figure size 720x432 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"rijpbCaF01"}],"key":"nXQ7iEeXL6"}],"key":"u5aBhOTBBF"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exercise 1.3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FvvWYu9kbe"}],"identifier":"exercise-1-3","label":"Exercise 1.3","html_id":"exercise-1-3","implicit":true,"key":"Tq2sStCAZO"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Interpret the plot. Which is the best regressor? Are any of the models overfitting? If so, what can we do to solve this? Is there a lot of variance in the results?","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"FaPcgDoZaY"}],"key":"PiBa4WcW7X"}],"key":"qB3jiKGPiQ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exercise 2: Regularization","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qpWiiW3m6K"}],"identifier":"exercise-2-regularization","label":"Exercise 2: Regularization","html_id":"exercise-2-regularization","implicit":true,"key":"Ca9q79zwPg"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"We will now tune these algorithm’s main regularization hyperparameter: the regularization hyperparameter (","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"WyKeRTlQg3"},{"type":"inlineCode","value":"alpha","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"AuvAiFooqg"},{"type":"text","value":") in Lasso and Ridge, and the number of neighbors (","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"bxV2fQbp1x"},{"type":"inlineCode","value":"n_neighbors","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"clgXkIzT8j"},{"type":"text","value":") in kNN.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Dbmg5brL4R"}],"key":"cgV4Klq8Qb"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"We expect the optimum for the alpha parameters to lie in ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"S26sbQU9b9"},{"type":"inlineMath","value":"[10^{-12},10^{12}]","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>12</mn></mrow></msup><mo separator=\"true\">,</mo><mn>1</mn><msup><mn>0</mn><mn>12</mn></msup><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[10^{-12},10^{12}]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">12</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">12</span></span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>","key":"DJrhKK12dJ"},{"type":"text","value":" and for n_neighbors between 1 and 50. alpha should be varied on a log scale (i.e. [0.01, 0.1, 1, 10, 100]), n_neighbors should be varied uniformly (i.e. [1,2,3,4]).","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"TjZgwuxyxK"}],"key":"wdoLcsHEYp"}],"key":"HryY523IA6"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exercise 2.1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aBHfvH7iNU"}],"identifier":"exercise-2-1","label":"Exercise 2.1","html_id":"exercise-2-1","implicit":true,"key":"H8hKIEp2k8"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Vary the hyperparameters in the range given above and, for each regressor, create a line plot that plots both the training and test score for every value of the regularization hyperparameter. Hence, you should produce 3 plots, one for each regressor. Use the default 5-fold cross validation for all scores, but only plot the means.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ijMO6W6Vwz"}],"key":"zOFaFweBKe"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Hints:","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"hxJ3jSXsDA"}],"key":"fGRDN1SlbR"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Think about the time complexity of these models. Trying too many hyperparameter values may take too much time.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"bnGC0ON4ou"}],"key":"wQ5qtB6m5s"}],"key":"o2LkKLqTVa"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"You can make use of numpy’s ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"QqUrXJ2A7p"},{"type":"link","url":"https://docs.scipy.org/doc/numpy/reference/generated/numpy.logspace.html","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"logspace","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"FGuY5KGoNW"}],"urlSource":"https://docs.scipy.org/doc/numpy/reference/generated/numpy.logspace.html","key":"a8Imi85YNm"},{"type":"text","value":", ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"wrKkrAinmG"},{"type":"link","url":"https://docs.scipy.org/doc/numpy/reference/generated/numpy.geomspace.html?highlight=geomspace#numpy.geomspace","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"geomspace","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"gqqtnI7YzD"}],"urlSource":"https://docs.scipy.org/doc/numpy/reference/generated/numpy.geomspace.html?highlight=geomspace#numpy.geomspace","key":"vxwSZL2nxu"},{"type":"text","value":", and ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"XgIdtXgZ6d"},{"type":"link","url":"https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html#numpy.linspace","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"linspace","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"lUrgKgoLLK"}],"urlSource":"https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html#numpy.linspace","key":"rLvByLN4NS"},{"type":"text","value":" functions.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"lTJvt9KteF"}],"key":"sDHeHPahfd"}],"key":"dE18XzTiI3"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"You can use matplotlib’s default ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"gFpxUsNfOl"},{"type":"link","url":"https://matplotlib.org/tutorials/introductory/pyplot.html","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"plot","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"sVygOlscju"}],"urlSource":"https://matplotlib.org/tutorials/introductory/pyplot.html","key":"Guci2vCfzM"},{"type":"text","value":" function to plot the train and test scores.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"AC9ufaWIQh"}],"key":"JCOIUXgfGc"}],"key":"Y5Htg2nU2Q"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"You can manually loop over the hyperparameter ranges, or you can already check out scikit-learn’s ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"Fum7V942aC"},{"type":"link","url":"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"GridSearchCV","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"Brhr00YHCQ"}],"urlSource":"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html","key":"fJEJoXJOZy"},{"type":"text","value":" function to save some programming. We’ll see it again later in the course.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"X1wMpGQ8VL"}],"key":"tXbjgTem8j"}],"key":"Li1MZj6CY1"}],"key":"gK9lXvkovh"}],"key":"WsGSbGRW1Q"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exercise 2.2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vbqLQiRbvY"}],"identifier":"exercise-2-2","label":"Exercise 2.2","html_id":"exercise-2-2","implicit":true,"key":"DJyuqgqfmf"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Interpret the plots. When are the methods underfitting? When are they overfitting? How sensitive are they to the regularization hyperparameter?","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"OywvlrN9nR"}],"key":"pUQGVnta1d"}],"key":"FR6je9cjtD"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exercise 2.3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pruAQLquOx"}],"identifier":"exercise-2-3","label":"Exercise 2.3","html_id":"exercise-2-3","implicit":true,"key":"ZvzKVhb8cd"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"ElasticNet allows to mix L1 and L2 loss, and the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"euUqYkd5hY"},{"type":"inlineCode","value":"l1_ratio","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"m7VOSRlklU"},{"type":"text","value":" hyperparameter defines the ratio of L1 loss. Hence, it has two interacting hyperparameters: l1_ratio and alpha. Run a grid search to obtain a matrix of l1_ratio and alpha values and the resulting cross-validation scores. Then, use the function provided below to plot a heatmap of all values and interpret the result. Can you explain how the two hyperparameters interact?","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ExSYrZcqdy"}],"key":"IP3zJ4QAbe"}],"key":"OaM9gWCTME"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Generic heatmap\ndef heatmap(values, xlabel, ylabel, xticklabels, yticklabels, cmap=None,\n            vmin=None, vmax=None, ax=None, fmt=\"%0.2f\", printvalues=False):\n    \"\"\"\n    Plots a heatmap for the performance of a model for every combination of two hyperparameter values\n    \n    values: nxn array with all evaluation results, varying the first hyperparameter first\n    xlabel: name of the first hyperparameter\n    ylabel: name of the second hyperparameter\n    xticklabels: values of the first hyperparameter\n    yticklabels: values of the second hyperparameter\n    cmap: colormap\n    vmin: minimal score\n    vmax: maximal score\n    ax: plot axes\n    fmt: format for printing the scores\n    printvalues: whether to print the scores\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n    img = ax.pcolor(values, cmap=cmap, vmin=None, vmax=None)\n    img.update_scalarmappable()\n    ax.set_xlabel(xlabel, fontsize=10)\n    ax.set_ylabel(ylabel, fontsize=10)\n    ax.set_xticks(np.arange(len(xticklabels)) + .5)\n    ax.set_yticks(np.arange(len(yticklabels)) + .5)\n    ax.set_xticklabels(xticklabels)\n    ax.set_yticklabels(yticklabels)\n    ax.set_aspect(1)\n    \n    ax.tick_params(axis='y', labelsize=12)\n    ax.tick_params(axis='x', labelsize=12, labelrotation=90)\n\n    if(printvalues):\n        for p, color, value in zip(img.get_paths(), img.get_facecolors(), img.get_array()):\n            x, y = p.vertices[:-2, :].mean(0)\n            if np.mean(color[:3]) > 0.5:\n                c = 'k'\n            else:\n                c = 'w'\n            ax.text(x, y, fmt % value, color=c, ha=\"center\", va=\"center\", size=10)\n    return img","key":"FuQAnsWZFE"},{"type":"outputs","id":"oXx8KPsEK-YIirmyYbDH2","children":[],"key":"oxNRoktMDI"}],"key":"QlGiLZZbkl"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exercise 3: Visualizing coefficients","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oOkk9cBHcJ"}],"identifier":"exercise-3-visualizing-coefficients","label":"Exercise 3: Visualizing coefficients","html_id":"exercise-3-visualizing-coefficients","implicit":true,"key":"NZsKLG8cUH"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Finally, let’s verify whether the different optimized linear models also find the same coefficients.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ZoCsDLbYN7"}],"key":"FGnfXXHwEu"},{"type":"heading","depth":3,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Exercise 3.1","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"Rww0NdMduL"}],"identifier":"exercise-3-1","label":"Exercise 3.1","html_id":"exercise-3-1","implicit":true,"key":"oBxT3EInyz"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Draw a ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"t8cxPyOT1U"},{"type":"link","url":"https://matplotlib.org/gallery/shapes_and_collections/scatter.html","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"scatterplot","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"SjEZmHjTLc"}],"urlSource":"https://matplotlib.org/gallery/shapes_and_collections/scatter.html","key":"UNoyxfr2oW"},{"type":"text","value":" plotting the coefficients of the different models in different colors. Do you see much difference between the different models?","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"vGBgdQ9jin"}],"key":"w7byJYTYG6"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"For all models, choose an alpha parameter that seems to work well in the previous exercise. When in doubt, use alpha=0.001.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"EjjOc2SA0q"}],"key":"r0PvmIDsrb"}],"key":"XBKSlwzLKZ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exercise 3.2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jCsud3h7BI"}],"identifier":"exercise-3-2","label":"Exercise 3.2","html_id":"exercise-3-2","implicit":true,"key":"Atl9Ikd7Cf"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Redraw the same plot but now using a large amount of regularization (e.g. alpha=1). What do you observe? Does this help you explain the performance difference between Ridge and Lasso in exercise 1.2?","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Z95hUNeiaP"}],"key":"ue8xOZlML3"}],"key":"cPntRyZqHO"}],"key":"OAANbjlHwa"},"references":{"cite":{"order":[],"data":{}}}}