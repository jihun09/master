{"version":3,"kind":"Notebook","sha256":"d88d9a494c0062c95cb8e2c4c27e774343d079381869578455b94fe19597b28d","slug":"labs.lab-6-transformers","location":"/labs/Lab 6 - Transformers.ipynb","dependencies":[],"frontmatter":{"title":"Lab 6: Transformers","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"mlcourse","language":"python"},"github":"https://github.com/ml-course/master","copyright":"2025. CC0 Licensed - Use as you like. Appropriate credit is very welcome","numbering":{"title":{"offset":1}},"source_url":"https://github.com/ml-course/master/blob/master/labs/Lab 6 - Transformers.ipynb","edit_url":"https://github.com/ml-course/master/edit/master/labs/Lab 6 - Transformers.ipynb","thumbnail":"/cifar100_example_ano-6e818a0059ffa985be31ca51355d6b6c.png","thumbnailOptimized":"/cifar100_example_ano-6e818a0059ffa985be31ca51355d6b6c.webp","exports":[{"format":"ipynb","filename":"Lab 6 - Transformers.ipynb","url":"/Lab 6 - Transformers-0abfd9e4ce2f14095779a623c8f81275.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In this lab, we will apply the transformer architecture from the tutorial to various tasks:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"oxuav6dE15"}],"key":"QSEhDDvzEe"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":4,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Sequence-to-Sequence modelling","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"sp3NNAs9Aa"}],"key":"uQbFZtN33Q"}],"key":"nvFVo8nI7x"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Set anomaly detection.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"w9QcWXro1c"}],"key":"rVUPB0kz7z"}],"key":"Ri2n6xcDSW"}],"key":"UWkjOWInGf"}],"key":"Lyd4aoWsm8"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Question 1: Sequence to Sequence","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Q80ptGk7MS"}],"identifier":"question-1-sequence-to-sequence","label":"Question 1: Sequence to Sequence","html_id":"question-1-sequence-to-sequence","implicit":true,"key":"e2coT57RCo"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"A Sequence-to-Sequence task represents a task where the input ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"VHBFS9K3Dq"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"and","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"mvIhhiEqwg"}],"key":"zhlu5rzzL0"},{"type":"text","value":" the output is a sequence, e.g. as in machine translation and summarization. Usually we would use an encoder-decoder architecture for this, but for now we’ll use only the encoder om a simple task: given a sequence of ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"x2Vk8gAId7"},{"type":"inlineMath","value":"N","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span>","key":"hxLJIvHsow"},{"type":"text","value":" numbers between ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gpgSZM0dfL"},{"type":"text","value":"0","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"UmCetp3DAq"},{"type":"text","value":" and ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PExPYXi5Ha"},{"type":"inlineMath","value":"M","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span></span></span></span>","key":"VWMDQ5ygmm"},{"type":"text","value":", the task is to reverse the input sequence. In Numpy notation, if our input is ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Wi6PJZrTf2"},{"type":"inlineMath","value":"x","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span>","key":"Ip8cgAqpgV"},{"type":"text","value":", the output should be ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PR9JhZtavi"},{"type":"inlineMath","value":"x","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span>","key":"p3IRszPpri"},{"type":"text","value":"[::-1].","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"v27EvjpjN0"}],"key":"sIRnuT0NYF"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The data","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ysZjgGV4m6"}],"identifier":"the-data","label":"The data","html_id":"the-data","implicit":true,"key":"hoBa1W63X3"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"First, let’s create a dataset class below.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"QJbNtqhn0A"}],"key":"NyfEyc87A1"}],"key":"EABQ5nxyWv"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"class ReverseDataset(data.Dataset):\n\n    def __init__(self, num_categories, seq_len, size):\n        super().__init__()\n        self.num_categories = num_categories\n        self.seq_len = seq_len\n        self.size = size\n        \n        self.data = torch.randint(self.num_categories, size=(self.size, self.seq_len))\n  \n    def __len__(self):\n        return self.size\n\n    def __getitem__(self, idx):\n        inp_data = self.data[idx]\n        labels = torch.flip(inp_data, dims=(0,))\n        return inp_data, labels","key":"cUw1ZrSmNN"},{"type":"outputs","id":"di9-hZ-gibmN-VqpnfOyi","children":[],"key":"z7J42RJlOG"}],"key":"xm3sZBne8N"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We create an arbitrary number of random sequences of numbers between 0 and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NiCwWQFVAJ"},{"type":"inlineCode","value":"num_categories-1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yt52OHLuYa"},{"type":"text","value":". The label is simply the tensor flipped over the sequence dimension. We can create the corresponding data loaders below.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tw3OtQpS8k"}],"key":"zYLTDiUPIq"}],"key":"MWJPoA9OM4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"dataset = partial(ReverseDataset, 10, 16)\ntrain_loader = data.DataLoader(dataset(50000), batch_size=128, shuffle=True, drop_last=True, pin_memory=True)\nval_loader   = data.DataLoader(dataset(1000), batch_size=128)\ntest_loader  = data.DataLoader(dataset(10000), batch_size=128)","key":"etWC8VY7uo"},{"type":"outputs","id":"MK029osh1Qo4LSTUe47Iy","children":[],"key":"o5XcRmAxSB"}],"key":"ojTPYFeo93"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s look at an arbitrary sample of the dataset:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qfaeznQlM6"}],"key":"JrFDYKjJI5"}],"key":"LgzMaGQsO4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"inp_data, labels = train_loader.dataset[0]\nprint(\"Input data:\", inp_data)\nprint(\"Labels:    \", labels)","key":"pVy5hOdpIX"},{"type":"outputs","id":"7WUQpbAqHs8B80sVj-FMy","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Input data: tensor([9, 6, 2, 0, 6, 2, 7, 9, 7, 3, 3, 4, 3, 7, 0, 9])\nLabels:     tensor([9, 0, 7, 3, 4, 3, 3, 7, 9, 7, 2, 6, 0, 2, 6, 9])\n"},"children":[],"key":"yyuvAXx7jH"}],"key":"yNph8lJyIY"}],"key":"xYsIAoMoOa"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The model","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"exDSWDUtEq"}],"identifier":"the-model","label":"The model","html_id":"the-model","implicit":true,"key":"aZgDPPzhSu"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Create a class ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"CGvG9JqUmu"},{"type":"inlineCode","value":"ReversePredictor","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Pr3VsHLOx7"},{"type":"text","value":", which extends the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"URJ6xU4VS7"},{"type":"inlineCode","value":"TransformerPredictor","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"pCcIBt1QNY"},{"type":"text","value":" we created in the tutorial. During training, pass the input sequence through the Transformer encoder and predict the output for each input token. You can use standard Cross-Entropy loss. Every number can be represented as a one-hot vector, or a learned embedding vector provided by the PyTorch module ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"IG18TKxtOw"},{"type":"inlineCode","value":"nn.Embedding","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"zU0IraI6Vm"},{"type":"text","value":".","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"GO58K5h77g"}],"key":"kl30vdNoOd"}],"key":"Mh2bfHz9wG"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Create a training function for PyTorch Lightning, and also test your model on the test set. Experiment with adding an additional parameter ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"I2YrCjCwMA"},{"type":"inlineCode","value":"gradient_clip_val","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"u06vO6tlkh"},{"type":"text","value":" that implements ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IfaW4vA0AD"},{"type":"link","url":"https://deepai.org/machine-learning-glossary-and-terms/gradient-clipping","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"gradient clipping","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"L5hC0Zs6vR"}],"urlSource":"https://deepai.org/machine-learning-glossary-and-terms/gradient-clipping","key":"MOIZLVWQYp"},{"type":"text","value":").","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IBPvArlAOK"}],"key":"ruvkXoz1Lu"}],"key":"M5nVj8Tu39"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The trainer","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"C9mQrcdNQQ"}],"identifier":"the-trainer","label":"The trainer","html_id":"the-trainer","implicit":true,"key":"lMYLDEHhPI"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Train the model, use a single encoder block and a single head in the Multi-Head Attention. This should be ok for this simple task.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"CTFRhVqF2w"}],"key":"BtOh351ZmN"}],"key":"TUjdJpscIw"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Visualization","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"akXEoDloSj"}],"identifier":"visualization","label":"Visualization","html_id":"visualization","implicit":true,"key":"EfATztq7eI"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Try to visualize the attention in the Multi-Head Attention block, for an arbitrary input. Next, create a plot where over rows, we have different layers, while over columns, we show the different heads, i.e. a matrix visualizing all the attention values.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"KqHKEo1o8O"}],"key":"QeOofKz3gc"}],"key":"Bk4sIr1rgJ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Set Anomaly Detection","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rmw8N0I3ki"}],"identifier":"set-anomaly-detection","label":"Set Anomaly Detection","html_id":"set-anomaly-detection","implicit":true,"key":"gLVpSZzTsa"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Transformers offer the perfect architecture for set problems as the Multi-Head Attention is permutation-equivariant, and thus, outputs the same values no matter in what order we enter the inputs (inputs and outputs are permuted equally). The task we are looking at for sets is ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"o0DUDfulYH"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Set Anomaly Detection","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"VS08afpKfo"}],"key":"ny6jUSl52l"},{"type":"text","value":" which means that we try to find the element(s) in a set that does not fit the others. A common application of anomaly detection is performed on a set of images, where ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"wCGYUAk37v"},{"type":"inlineMath","value":"N-1","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">N-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span>","key":"OaTQFvGe0o"},{"type":"text","value":" images belong to the same category/have the same high-level features while one belongs to another category. Note that category does not necessarily have to relate to a class in a standard classification problem, but could be the combination of multiple features. For instance, on a face dataset, this could be people with glasses, male, beard, etc. An example of distinguishing different animals can be seen below. The first four images show foxes, while the last represents a different animal. We want to recognize that the last image shows a different animal, but it is not relevant which class of animal it is.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"r2KgKFRXTc"}],"key":"t0L0WARsGm"},{"type":"paragraph","children":[{"type":"image","url":"/cifar100_example_ano-6e818a0059ffa985be31ca51355d6b6c.png","width":"600px","key":"wo94CCfGby","urlSource":"../notebooks/images/cifar100_example_anomaly.png","urlOptimized":"/cifar100_example_ano-6e818a0059ffa985be31ca51355d6b6c.webp"}],"key":"NuDoUmlt0O"},{"type":"heading","depth":3,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"The data","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"vsBCxyyRHN"}],"identifier":"the-data","label":"The data","html_id":"the-data-1","implicit":true,"key":"AJ0QPQgWcQ"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"We will use the CIFAR100 dataset. CIFAR100 has 600 images for 100 classes each with a resolution of 32x32, similar to CIFAR10. The larger amount of classes requires the model to attend to specific features in the images instead of coarse features as in CIFAR10, therefore making the task harder. We will show the model a set of 9 images of one class, and 1 image from another class. The task is to find the image that is from a different class than the other images.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"mFRako0o3s"}],"key":"PkIw212458"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Using the raw images directly as input to the Transformer is not a good idea, because it is not translation invariant as a CNN. Use a pre-trained ResNet34 model from the torchvision package to obtain high-level, low-dimensional features of the images. Below, we will load the dataset.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"Z5JwnBvngk"}],"key":"WZ13dxyDQZ"}],"key":"NX091uR6qy"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# ImageNet statistics\nDATA_MEANS = np.array([0.485, 0.456, 0.406])\nDATA_STD = np.array([0.229, 0.224, 0.225])\n# As torch tensors for later preprocessing\nTORCH_DATA_MEANS = torch.from_numpy(DATA_MEANS).view(1,3,1,1)\nTORCH_DATA_STD = torch.from_numpy(DATA_STD).view(1,3,1,1)\n\n# Resize to 224x224, and normalize to ImageNet statistic\ntransform = transforms.Compose([transforms.Resize((224,224)),\n                                transforms.ToTensor(),\n                                transforms.Normalize(DATA_MEANS, DATA_STD)\n                                ])\n# Loading the training dataset. \ntrain_set = CIFAR100(root=DATASET_PATH, train=True, transform=transform, download=True)\n\n# Loading the test set\ntest_set = CIFAR100(root=DATASET_PATH, train=False, transform=transform, download=True)","key":"LmYjyKMT3m"},{"type":"outputs","id":"U4wvEo9OAz2uJmjUqdZLe","children":[{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"100%|██████████| 169M/169M [00:07<00:00, 22.1MB/s] \n"},"children":[],"key":"xLHWHBDJMq"}],"key":"WL0YzzyN82"}],"key":"cZdRwZS9EF"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Next, run a pre-trained ResNet model on the images, and extract the features before the classification layer. These are the most high-level features, and should sufficiently describe the images. As we don’t have a large enough dataset and want to train our model efficiently, it’s best to extract the features beforehand.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"f1SXtOZd8i"}],"key":"UxoZ0kvTd8"}],"key":"tnZNVSFfXy"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This is a validation set to detect when we should stop training. In this case, we will split the training set into 90% training, 10% validation in a balanced way.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SUz9q67Kto"}],"key":"victQ0bmcX"}],"key":"R00bKuAeqp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"## Split train into train+val\n# Get labels from train set\nlabels = train_set.targets\n\n# Get indices of images per class\nlabels = torch.LongTensor(labels)\nnum_labels = labels.max()+1\nsorted_indices = torch.argsort(labels).reshape(num_labels, -1) # [classes, num_imgs per class]\n\n# Determine number of validation images per class\nnum_val_exmps = sorted_indices.shape[1] // 10\n\n# Get image indices for validation and training\nval_indices   = sorted_indices[:,:num_val_exmps].reshape(-1)\ntrain_indices = sorted_indices[:,num_val_exmps:].reshape(-1)\n\n# Group corresponding image features and labels\ntrain_feats, train_labels = train_set_feats[train_indices], labels[train_indices]\nval_feats,   val_labels   = train_set_feats[val_indices],   labels[val_indices]","key":"q4XKgX9yg5"},{"type":"outputs","id":"srovKRdRL3T9H63FdO5BC","children":[],"key":"ibZob3IsRZ"}],"key":"SI8xGqJIt0"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We create a dataset class for the set anomaly task. We define an epoch to be the sequence in which each image has been exactly once as an “anomaly”. Hence, the length of the dataset is the number of images in it. For the training set, each time we access an item with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mrpI6CFgZ2"},{"type":"inlineCode","value":"__getitem__","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"eSrxx18G0h"},{"type":"text","value":", we sample a random, different class than the image at the corresponding index ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"v8DawgNJPv"},{"type":"inlineCode","value":"idx","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NIUdzSuAYJ"},{"type":"text","value":" has. In a second step, we sample ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QuPoGXlmxs"},{"type":"inlineMath","value":"N-1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">N-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span>","key":"X3Sh7sbwjI"},{"type":"text","value":" images of this sampled class. The set of 10 images is finally returned. The randomness in the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"afNMQkcuAT"},{"type":"inlineCode","value":"__getitem__","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nm7bPF7hlK"},{"type":"text","value":" allows us to see a slightly different set during each iteration. However, we can’t use the same strategy for the test set as we want the test dataset to be the same every time we iterate over it. Hence, we sample the sets in the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KCYLorI84A"},{"type":"inlineCode","value":"__init__","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"idMWg5icgr"},{"type":"text","value":" method, and return those in ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cf5jzr2p5X"},{"type":"inlineCode","value":"__getitem__","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FtW2p4hG3N"},{"type":"text","value":". The code below implements exactly this dynamic.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xciMMeNxbd"}],"key":"A9N9bSqt8i"}],"key":"n9Is2Ub2HU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"class SetAnomalyDataset(data.Dataset):\n    \n    def __init__(self, img_feats, labels, set_size=10, train=True):\n        \"\"\"\n        Inputs:\n            img_feats - Tensor of shape [num_imgs, img_dim]. Represents the high-level features.\n            labels - Tensor of shape [num_imgs], containing the class labels for the images\n            set_size - Number of elements in a set. N-1 are sampled from one class, and one from another one.\n            train - If True, a new set will be sampled every time __getitem__ is called.\n        \"\"\"\n        super().__init__()\n        self.img_feats = img_feats\n        self.labels = labels\n        self.set_size = set_size-1 # The set size is here the size of correct images\n        self.train = train\n        \n        # Tensors with indices of the images per class\n        self.num_labels = labels.max()+1\n        self.img_idx_by_label = torch.argsort(self.labels).reshape(self.num_labels, -1)\n        \n        if not train:\n            self.test_sets = self._create_test_sets()\n            \n            \n    def _create_test_sets(self):\n        # Pre-generates the sets for each image for the test set\n        test_sets = []\n        num_imgs = self.img_feats.shape[0]\n        np.random.seed(42)\n        test_sets = [self.sample_img_set(self.labels[idx]) for idx in range(num_imgs)]\n        test_sets = torch.stack(test_sets, dim=0)\n        return test_sets\n            \n        \n    def sample_img_set(self, anomaly_label):\n        \"\"\"\n        Samples a new set of images, given the label of the anomaly. \n        The sampled images come from a different class than anomaly_label\n        \"\"\"\n        # Sample class from 0,...,num_classes-1 while skipping anomaly_label as class\n        set_label = np.random.randint(self.num_labels-1)\n        if set_label >= anomaly_label:\n            set_label += 1\n            \n        # Sample images from the class determined above\n        img_indices = np.random.choice(self.img_idx_by_label.shape[1], size=self.set_size, replace=False)\n        img_indices = self.img_idx_by_label[set_label, img_indices]\n        return img_indices\n        \n        \n    def __len__(self):\n        return self.img_feats.shape[0]\n    \n    \n    def __getitem__(self, idx):\n        anomaly = self.img_feats[idx]\n        if self.train: # If train => sample\n            img_indices = self.sample_img_set(self.labels[idx])\n        else: # If test => use pre-generated ones\n            img_indices = self.test_sets[idx]\n            \n        # Concatenate images. The anomaly is always the last image for simplicity\n        img_set = torch.cat([self.img_feats[img_indices], anomaly[None]], dim=0)\n        indices = torch.cat([img_indices, torch.LongTensor([idx])], dim=0)\n        label = img_set.shape[0]-1\n        \n        # We return the indices of the images for visualization purpose. \"Label\" is the index of the anomaly\n        return img_set, indices, label","key":"YH5P4x3mDz"},{"type":"outputs","id":"xCCcuecd0ICnLd2iyEq1M","children":[],"key":"BcAPflnCBP"}],"key":"p8xslTx9CU"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Next, we can setup our datasets and data loaders below. Here, we will use a set size of 10, i.e. 9 images from one category + 1 anomaly. Feel free to change it if you want to experiment with the sizes.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"a7SXkLr304"}],"key":"E68kk1J4Pu"}],"key":"t0xec62A7y"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"SET_SIZE = 10\ntest_labels = torch.LongTensor(test_set.targets)\n\ntrain_anom_dataset = SetAnomalyDataset(train_feats, train_labels, set_size=SET_SIZE, train=True)\nval_anom_dataset   = SetAnomalyDataset(val_feats,   val_labels,   set_size=SET_SIZE, train=False)\ntest_anom_dataset  = SetAnomalyDataset(test_feats,  test_labels,  set_size=SET_SIZE, train=False)\n\ntrain_anom_loader = data.DataLoader(train_anom_dataset, batch_size=64, shuffle=True,  drop_last=True,  num_workers=0, pin_memory=True)\nval_anom_loader   = data.DataLoader(val_anom_dataset,   batch_size=64, shuffle=False, drop_last=False, num_workers=0)\ntest_anom_loader  = data.DataLoader(test_anom_dataset,  batch_size=64, shuffle=False, drop_last=False, num_workers=0)","key":"p2RquUav8F"},{"type":"outputs","id":"hX-N-8D9KIFI2rIJ_9umC","children":[],"key":"D4Z8EntzAw"}],"key":"PIolESWTUW"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To understand the dataset a little better, we can plot below a few sets from the test dataset. Each row shows a different input set, where the first 9 are from the same class.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RGcmTytl6A"}],"key":"aseEpvxbt0"}],"key":"gJgcuFCH2b"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def visualize_exmp(indices, orig_dataset):\n    images = [orig_dataset[idx][0] for idx in indices.reshape(-1)]\n    images = torch.stack(images, dim=0)\n    images = images * TORCH_DATA_STD + TORCH_DATA_MEANS\n    \n    img_grid = torchvision.utils.make_grid(images, nrow=SET_SIZE, normalize=True, pad_value=0.5, padding=16)\n    img_grid = img_grid.permute(1, 2, 0)\n\n    plt.figure(figsize=(12,8))\n    plt.title(\"Anomaly examples on CIFAR100\")\n    plt.imshow(img_grid)\n    plt.axis('off')\n    plt.show()\n    plt.close()\n\n_, indices, _ = next(iter(test_anom_loader))\nvisualize_exmp(indices[:4], test_set)","key":"vgvXCSSLW1"},{"type":"outputs","id":"jzwGuvtALb5jjysCX7HxU","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"9e48f34ae37c1839aad5207b99657286","path":"/9e48f34ae37c1839aad5207b99657286.png"},"text/plain":{"content":"<Figure size 1200x800 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"wrFR166uZ0"}],"key":"V7iajg4aLO"}],"key":"HlivvbOChI"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can already see that for some sets the task might be easier than for others. Difficulties can especially arise if the anomaly is in a different, but yet visually similar class (e.g. train vs bus, flour vs worm, etc.).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KR8NUcvTdZ"}],"key":"I3XCCsm6NP"},{"type":"heading","depth":3,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The model","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"LwCUtSSW5f"}],"identifier":"the-model","label":"The model","html_id":"the-model-1","implicit":true,"key":"ENBlWUKVa1"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Write a model to classify whole set. For the prediction to be permutation-equivariant, output one logit for each image. Over these logits, apply a softmax and train the anomaly image to have the highest score/probability.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"K1cNkU4uFN"}],"key":"R5AtfIwwAy"}],"key":"MA0tTz9XUi"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The trainer","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ggCr1z5ygm"}],"identifier":"the-trainer","label":"The trainer","html_id":"the-trainer-1","implicit":true,"key":"CzdmS7v5Oq"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Finally, write your train function below. It can have the exact same structure as the reverse task one. Train your model.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"WFP7lBZs0o"}],"key":"xXFNdJ1GKF"}],"key":"bgi8prYCCQ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Visualization","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FcRKRRwp5U"}],"identifier":"visualization","label":"Visualization","html_id":"visualization-1","implicit":true,"key":"Vpmml1j86k"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"To interpret the model a little more, we plot the attention maps inside the model. This should give you an idea of what information the model is sharing/communicating between images, and what each head might represent. Write a plot function which plots the images in the input set, the prediction of the model, and the attention maps of the different heads on layers of the transformer. Feel free to explore the attention maps for different input examples as well.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"zq2zam7mCE"}],"key":"oqoAeQDbdf"}],"key":"n2q8O2UShX"}],"key":"FnNBS5dv5H"},"references":{"cite":{"order":[],"data":{}}}}